{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ie-kZh-WdDTT",
        "outputId": "a579ba59-922c-4219-dfb5-976f1319c52e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.18.0+cu121)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.7.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.25.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (24.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105\n"
          ]
        }
      ],
      "source": [
        "pip install torch torchvision matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "l6ekVt6adEDP"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = datasets.MNIST(root= 'data', train=True, transform= ToTensor(), download=True)\n",
        "test_data = datasets.MNIST(root= 'data', train=False, transform= ToTensor(), download=True)  # Testing data therefore training is set to False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Omoy432dfac",
        "outputId": "8e9d3a51-bf00-47cc-b794-becc56e7b78b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 17117172.19it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 483006.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 4367719.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 2898300.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data  # 60,000 datapoints"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XK7_70JFd8bD",
        "outputId": "0d1ba792-0cfb-4b61-ef08-e18059abd5da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 60000\n",
              "    Root location: data\n",
              "    Split: Train\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data  # note that this only has 10,000 datapoints"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6NRTmSseBa5",
        "outputId": "ba36e0d3-85da-4a71-d961-5ca78a9cad9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 10000\n",
              "    Root location: data\n",
              "    Split: Test\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.targets  # the individual class ie numbers from 0 to 9"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeWn5K49eHYg",
        "outputId": "57c4db60-7cee-4e5b-e8dd-d5490726991e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([5, 0, 4,  ..., 5, 6, 8])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaders = {\n",
        "    'train': DataLoader(\n",
        "        train_data,\n",
        "        batch_size=100,\n",
        "        shuffle=True,\n",
        "        num_workers=1\n",
        "    ),\n",
        "    'test': DataLoader(\n",
        "        test_data,\n",
        "        batch_size=100,\n",
        "        shuffle=True,\n",
        "        num_workers=1\n",
        "    )\n",
        "}"
      ],
      "metadata": {
        "id": "IR62_AHYenIk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(loaders)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqjIivQsgsjk",
        "outputId": "35b24b65-7353-4183-b1ec-1554a44b00f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'train': <torch.utils.data.dataloader.DataLoader object at 0x7895f4c01210>, 'test': <torch.utils.data.dataloader.DataLoader object at 0x7895f4c011e0>}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loaders"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1aMcxEZgtN4",
        "outputId": "44c0f6ae-2e96-4da1-e9c0-a89433b82032"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': <torch.utils.data.dataloader.DataLoader at 0x7895f4c01210>,\n",
              " 'test': <torch.utils.data.dataloader.DataLoader at 0x7895f4c011e0>}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "V4TGTsEPgws8"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(CNN, self).__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "    self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "    self.conv2_drop = nn.Dropout2d()\n",
        "    self.fc1 = nn.Linear(320, 50)\n",
        "    self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "    x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "    x = x.view(-1, 320)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.dropout(x, training=self.training)\n",
        "    x = self.fc2(x)\n",
        "\n",
        "    return F.softmax(x)\n",
        "\n",
        "#  Here you have the full architecture of the CNN -- we still need to train and test it"
      ],
      "metadata": {
        "id": "71IntN9AzglK"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model= CNN().to(device)  # moving everything to the device if we do have a cude gpu available\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def train(epoch):\n",
        "  model.train()\n",
        "  for batch_idx, (data, target) in enumerate(loaders['train']):\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    output = model(data)\n",
        "    loss = loss_fn(output, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if batch_idx % 20 == 0:\n",
        "      print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(loaders[\"train\"].dataset)} ({100. * batch_idx / len(loaders[\"train\"]):.0f}%)]\\t{loss.item():.6f}')\n",
        "\n",
        "\n",
        "def test():  # test therefore no epochs paramater\n",
        "  model.eval()\n",
        "\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for data, target in loaders[\"test\"]:\n",
        "      data, target = data.to(device), target.to(device)\n",
        "      output = model(data)\n",
        "      test_loss += loss_fn(output, target).item()\n",
        "      pred = output.argmax(dim=1, keepdim=True)\n",
        "      correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "  test_loss /= len(loaders[\"test\"].dataset)\n",
        "  print(f'\\nTest set: Average loss: {test_loss: 4f}, Accuracy {correct}/{len(loaders[\"test\"].dataset)} ({100. * correct / len(loaders[\"test\"].dataset):.0f}%\\n)')\n",
        "\n"
      ],
      "metadata": {
        "id": "ThoSqwuJ1awH"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we can start the training now\n",
        "\n",
        "for epoch in range(1, 11):\n",
        "  train(epoch)\n",
        "  test()  # 98% accuracy which is great!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6K6ofDpOTWq",
        "outputId": "97657619-2107-44b9-9075-930e4856f87b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-0a9cb36f43b8>:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.softmax(x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\t1.508449\n",
            "Train Epoch: 1 [2000/60000 (3%)]\t1.518146\n",
            "Train Epoch: 1 [4000/60000 (7%)]\t1.494835\n",
            "Train Epoch: 1 [6000/60000 (10%)]\t1.535080\n",
            "Train Epoch: 1 [8000/60000 (13%)]\t1.539660\n",
            "Train Epoch: 1 [10000/60000 (17%)]\t1.508091\n",
            "Train Epoch: 1 [12000/60000 (20%)]\t1.511023\n",
            "Train Epoch: 1 [14000/60000 (23%)]\t1.519872\n",
            "Train Epoch: 1 [16000/60000 (27%)]\t1.538100\n",
            "Train Epoch: 1 [18000/60000 (30%)]\t1.504233\n",
            "Train Epoch: 1 [20000/60000 (33%)]\t1.546545\n",
            "Train Epoch: 1 [22000/60000 (37%)]\t1.556035\n",
            "Train Epoch: 1 [24000/60000 (40%)]\t1.589998\n",
            "Train Epoch: 1 [26000/60000 (43%)]\t1.512392\n",
            "Train Epoch: 1 [28000/60000 (47%)]\t1.501809\n",
            "Train Epoch: 1 [30000/60000 (50%)]\t1.504684\n",
            "Train Epoch: 1 [32000/60000 (53%)]\t1.574888\n",
            "Train Epoch: 1 [34000/60000 (57%)]\t1.561221\n",
            "Train Epoch: 1 [36000/60000 (60%)]\t1.532894\n",
            "Train Epoch: 1 [38000/60000 (63%)]\t1.547708\n",
            "Train Epoch: 1 [40000/60000 (67%)]\t1.537821\n",
            "Train Epoch: 1 [42000/60000 (70%)]\t1.574266\n",
            "Train Epoch: 1 [44000/60000 (73%)]\t1.514768\n",
            "Train Epoch: 1 [46000/60000 (77%)]\t1.541150\n",
            "Train Epoch: 1 [48000/60000 (80%)]\t1.530333\n",
            "Train Epoch: 1 [50000/60000 (83%)]\t1.496101\n",
            "Train Epoch: 1 [52000/60000 (87%)]\t1.551003\n",
            "Train Epoch: 1 [54000/60000 (90%)]\t1.511956\n",
            "Train Epoch: 1 [56000/60000 (93%)]\t1.528764\n",
            "Train Epoch: 1 [58000/60000 (97%)]\t1.543673\n",
            "\n",
            "Test set: Average loss:  0.014835, Accuracy 9772/10000 (98%\n",
            ")\n",
            "Train Epoch: 2 [0/60000 (0%)]\t1.561623\n",
            "Train Epoch: 2 [2000/60000 (3%)]\t1.500700\n",
            "Train Epoch: 2 [4000/60000 (7%)]\t1.511563\n",
            "Train Epoch: 2 [6000/60000 (10%)]\t1.553200\n",
            "Train Epoch: 2 [8000/60000 (13%)]\t1.544195\n",
            "Train Epoch: 2 [10000/60000 (17%)]\t1.471203\n",
            "Train Epoch: 2 [12000/60000 (20%)]\t1.496482\n",
            "Train Epoch: 2 [14000/60000 (23%)]\t1.555370\n",
            "Train Epoch: 2 [16000/60000 (27%)]\t1.559520\n",
            "Train Epoch: 2 [18000/60000 (30%)]\t1.512646\n",
            "Train Epoch: 2 [20000/60000 (33%)]\t1.527793\n",
            "Train Epoch: 2 [22000/60000 (37%)]\t1.545431\n",
            "Train Epoch: 2 [24000/60000 (40%)]\t1.501775\n",
            "Train Epoch: 2 [26000/60000 (43%)]\t1.510221\n",
            "Train Epoch: 2 [28000/60000 (47%)]\t1.526075\n",
            "Train Epoch: 2 [30000/60000 (50%)]\t1.515555\n",
            "Train Epoch: 2 [32000/60000 (53%)]\t1.501952\n",
            "Train Epoch: 2 [34000/60000 (57%)]\t1.540095\n",
            "Train Epoch: 2 [36000/60000 (60%)]\t1.481670\n",
            "Train Epoch: 2 [38000/60000 (63%)]\t1.513371\n",
            "Train Epoch: 2 [40000/60000 (67%)]\t1.522646\n",
            "Train Epoch: 2 [42000/60000 (70%)]\t1.523180\n",
            "Train Epoch: 2 [44000/60000 (73%)]\t1.491761\n",
            "Train Epoch: 2 [46000/60000 (77%)]\t1.506883\n",
            "Train Epoch: 2 [48000/60000 (80%)]\t1.519167\n",
            "Train Epoch: 2 [50000/60000 (83%)]\t1.513873\n",
            "Train Epoch: 2 [52000/60000 (87%)]\t1.492761\n",
            "Train Epoch: 2 [54000/60000 (90%)]\t1.505974\n",
            "Train Epoch: 2 [56000/60000 (93%)]\t1.515356\n",
            "Train Epoch: 2 [58000/60000 (97%)]\t1.485509\n",
            "\n",
            "Test set: Average loss:  0.014830, Accuracy 9781/10000 (98%\n",
            ")\n",
            "Train Epoch: 3 [0/60000 (0%)]\t1.487188\n",
            "Train Epoch: 3 [2000/60000 (3%)]\t1.503318\n",
            "Train Epoch: 3 [4000/60000 (7%)]\t1.501911\n",
            "Train Epoch: 3 [6000/60000 (10%)]\t1.477367\n",
            "Train Epoch: 3 [8000/60000 (13%)]\t1.516951\n",
            "Train Epoch: 3 [10000/60000 (17%)]\t1.514711\n",
            "Train Epoch: 3 [12000/60000 (20%)]\t1.518275\n",
            "Train Epoch: 3 [14000/60000 (23%)]\t1.521914\n",
            "Train Epoch: 3 [16000/60000 (27%)]\t1.506231\n",
            "Train Epoch: 3 [18000/60000 (30%)]\t1.487262\n",
            "Train Epoch: 3 [20000/60000 (33%)]\t1.534939\n",
            "Train Epoch: 3 [22000/60000 (37%)]\t1.505707\n",
            "Train Epoch: 3 [24000/60000 (40%)]\t1.535242\n",
            "Train Epoch: 3 [26000/60000 (43%)]\t1.529959\n",
            "Train Epoch: 3 [28000/60000 (47%)]\t1.533145\n",
            "Train Epoch: 3 [30000/60000 (50%)]\t1.486029\n",
            "Train Epoch: 3 [32000/60000 (53%)]\t1.553717\n",
            "Train Epoch: 3 [34000/60000 (57%)]\t1.522818\n",
            "Train Epoch: 3 [36000/60000 (60%)]\t1.498398\n",
            "Train Epoch: 3 [38000/60000 (63%)]\t1.536448\n",
            "Train Epoch: 3 [40000/60000 (67%)]\t1.494076\n",
            "Train Epoch: 3 [42000/60000 (70%)]\t1.487905\n",
            "Train Epoch: 3 [44000/60000 (73%)]\t1.499438\n",
            "Train Epoch: 3 [46000/60000 (77%)]\t1.529505\n",
            "Train Epoch: 3 [48000/60000 (80%)]\t1.521591\n",
            "Train Epoch: 3 [50000/60000 (83%)]\t1.544571\n",
            "Train Epoch: 3 [52000/60000 (87%)]\t1.503551\n",
            "Train Epoch: 3 [54000/60000 (90%)]\t1.497323\n",
            "Train Epoch: 3 [56000/60000 (93%)]\t1.562080\n",
            "Train Epoch: 3 [58000/60000 (97%)]\t1.506507\n",
            "\n",
            "Test set: Average loss:  0.014817, Accuracy 9796/10000 (98%\n",
            ")\n",
            "Train Epoch: 4 [0/60000 (0%)]\t1.523206\n",
            "Train Epoch: 4 [2000/60000 (3%)]\t1.484223\n",
            "Train Epoch: 4 [4000/60000 (7%)]\t1.508176\n",
            "Train Epoch: 4 [6000/60000 (10%)]\t1.509484\n",
            "Train Epoch: 4 [8000/60000 (13%)]\t1.509751\n",
            "Train Epoch: 4 [10000/60000 (17%)]\t1.497264\n",
            "Train Epoch: 4 [12000/60000 (20%)]\t1.500546\n",
            "Train Epoch: 4 [14000/60000 (23%)]\t1.506071\n",
            "Train Epoch: 4 [16000/60000 (27%)]\t1.543957\n",
            "Train Epoch: 4 [18000/60000 (30%)]\t1.510550\n",
            "Train Epoch: 4 [20000/60000 (33%)]\t1.517784\n",
            "Train Epoch: 4 [22000/60000 (37%)]\t1.516109\n",
            "Train Epoch: 4 [24000/60000 (40%)]\t1.476783\n",
            "Train Epoch: 4 [26000/60000 (43%)]\t1.512691\n",
            "Train Epoch: 4 [28000/60000 (47%)]\t1.515284\n",
            "Train Epoch: 4 [30000/60000 (50%)]\t1.518468\n",
            "Train Epoch: 4 [32000/60000 (53%)]\t1.500083\n",
            "Train Epoch: 4 [34000/60000 (57%)]\t1.500679\n",
            "Train Epoch: 4 [36000/60000 (60%)]\t1.555685\n",
            "Train Epoch: 4 [38000/60000 (63%)]\t1.481694\n",
            "Train Epoch: 4 [40000/60000 (67%)]\t1.536504\n",
            "Train Epoch: 4 [42000/60000 (70%)]\t1.530501\n",
            "Train Epoch: 4 [44000/60000 (73%)]\t1.530207\n",
            "Train Epoch: 4 [46000/60000 (77%)]\t1.513879\n",
            "Train Epoch: 4 [48000/60000 (80%)]\t1.476888\n",
            "Train Epoch: 4 [50000/60000 (83%)]\t1.513145\n",
            "Train Epoch: 4 [52000/60000 (87%)]\t1.531641\n",
            "Train Epoch: 4 [54000/60000 (90%)]\t1.504777\n",
            "Train Epoch: 4 [56000/60000 (93%)]\t1.520538\n",
            "Train Epoch: 4 [58000/60000 (97%)]\t1.546211\n",
            "\n",
            "Test set: Average loss:  0.014809, Accuracy 9802/10000 (98%\n",
            ")\n",
            "Train Epoch: 5 [0/60000 (0%)]\t1.510544\n",
            "Train Epoch: 5 [2000/60000 (3%)]\t1.462851\n",
            "Train Epoch: 5 [4000/60000 (7%)]\t1.504778\n",
            "Train Epoch: 5 [6000/60000 (10%)]\t1.544956\n",
            "Train Epoch: 5 [8000/60000 (13%)]\t1.526565\n",
            "Train Epoch: 5 [10000/60000 (17%)]\t1.522700\n",
            "Train Epoch: 5 [12000/60000 (20%)]\t1.536263\n",
            "Train Epoch: 5 [14000/60000 (23%)]\t1.507932\n",
            "Train Epoch: 5 [16000/60000 (27%)]\t1.493527\n",
            "Train Epoch: 5 [18000/60000 (30%)]\t1.541819\n",
            "Train Epoch: 5 [20000/60000 (33%)]\t1.526251\n",
            "Train Epoch: 5 [22000/60000 (37%)]\t1.483085\n",
            "Train Epoch: 5 [24000/60000 (40%)]\t1.495470\n",
            "Train Epoch: 5 [26000/60000 (43%)]\t1.519125\n",
            "Train Epoch: 5 [28000/60000 (47%)]\t1.543477\n",
            "Train Epoch: 5 [30000/60000 (50%)]\t1.521064\n",
            "Train Epoch: 5 [32000/60000 (53%)]\t1.541229\n",
            "Train Epoch: 5 [34000/60000 (57%)]\t1.529340\n",
            "Train Epoch: 5 [36000/60000 (60%)]\t1.509086\n",
            "Train Epoch: 5 [38000/60000 (63%)]\t1.496122\n",
            "Train Epoch: 5 [40000/60000 (67%)]\t1.482208\n",
            "Train Epoch: 5 [42000/60000 (70%)]\t1.472259\n",
            "Train Epoch: 5 [44000/60000 (73%)]\t1.535284\n",
            "Train Epoch: 5 [46000/60000 (77%)]\t1.550231\n",
            "Train Epoch: 5 [48000/60000 (80%)]\t1.538793\n",
            "Train Epoch: 5 [50000/60000 (83%)]\t1.533339\n",
            "Train Epoch: 5 [52000/60000 (87%)]\t1.496286\n",
            "Train Epoch: 5 [54000/60000 (90%)]\t1.504333\n",
            "Train Epoch: 5 [56000/60000 (93%)]\t1.512583\n",
            "Train Epoch: 5 [58000/60000 (97%)]\t1.484411\n",
            "\n",
            "Test set: Average loss:  0.014810, Accuracy 9804/10000 (98%\n",
            ")\n",
            "Train Epoch: 6 [0/60000 (0%)]\t1.523431\n",
            "Train Epoch: 6 [2000/60000 (3%)]\t1.532145\n",
            "Train Epoch: 6 [4000/60000 (7%)]\t1.525974\n",
            "Train Epoch: 6 [6000/60000 (10%)]\t1.520973\n",
            "Train Epoch: 6 [8000/60000 (13%)]\t1.510247\n",
            "Train Epoch: 6 [10000/60000 (17%)]\t1.516769\n",
            "Train Epoch: 6 [12000/60000 (20%)]\t1.504421\n",
            "Train Epoch: 6 [14000/60000 (23%)]\t1.511399\n",
            "Train Epoch: 6 [16000/60000 (27%)]\t1.518341\n",
            "Train Epoch: 6 [18000/60000 (30%)]\t1.515889\n",
            "Train Epoch: 6 [20000/60000 (33%)]\t1.508144\n",
            "Train Epoch: 6 [22000/60000 (37%)]\t1.522207\n",
            "Train Epoch: 6 [24000/60000 (40%)]\t1.519673\n",
            "Train Epoch: 6 [26000/60000 (43%)]\t1.493347\n",
            "Train Epoch: 6 [28000/60000 (47%)]\t1.561495\n",
            "Train Epoch: 6 [30000/60000 (50%)]\t1.504465\n",
            "Train Epoch: 6 [32000/60000 (53%)]\t1.507780\n",
            "Train Epoch: 6 [34000/60000 (57%)]\t1.569211\n",
            "Train Epoch: 6 [36000/60000 (60%)]\t1.527522\n",
            "Train Epoch: 6 [38000/60000 (63%)]\t1.516734\n",
            "Train Epoch: 6 [40000/60000 (67%)]\t1.547391\n",
            "Train Epoch: 6 [42000/60000 (70%)]\t1.479443\n",
            "Train Epoch: 6 [44000/60000 (73%)]\t1.515110\n",
            "Train Epoch: 6 [46000/60000 (77%)]\t1.575552\n",
            "Train Epoch: 6 [48000/60000 (80%)]\t1.485086\n",
            "Train Epoch: 6 [50000/60000 (83%)]\t1.509488\n",
            "Train Epoch: 6 [52000/60000 (87%)]\t1.517169\n",
            "Train Epoch: 6 [54000/60000 (90%)]\t1.532344\n",
            "Train Epoch: 6 [56000/60000 (93%)]\t1.512070\n",
            "Train Epoch: 6 [58000/60000 (97%)]\t1.513590\n",
            "\n",
            "Test set: Average loss:  0.014809, Accuracy 9803/10000 (98%\n",
            ")\n",
            "Train Epoch: 7 [0/60000 (0%)]\t1.490922\n",
            "Train Epoch: 7 [2000/60000 (3%)]\t1.498914\n",
            "Train Epoch: 7 [4000/60000 (7%)]\t1.528989\n",
            "Train Epoch: 7 [6000/60000 (10%)]\t1.544091\n",
            "Train Epoch: 7 [8000/60000 (13%)]\t1.529417\n",
            "Train Epoch: 7 [10000/60000 (17%)]\t1.515282\n",
            "Train Epoch: 7 [12000/60000 (20%)]\t1.530171\n",
            "Train Epoch: 7 [14000/60000 (23%)]\t1.502794\n",
            "Train Epoch: 7 [16000/60000 (27%)]\t1.495792\n",
            "Train Epoch: 7 [18000/60000 (30%)]\t1.464140\n",
            "Train Epoch: 7 [20000/60000 (33%)]\t1.495937\n",
            "Train Epoch: 7 [22000/60000 (37%)]\t1.542860\n",
            "Train Epoch: 7 [24000/60000 (40%)]\t1.501753\n",
            "Train Epoch: 7 [26000/60000 (43%)]\t1.541619\n",
            "Train Epoch: 7 [28000/60000 (47%)]\t1.509376\n",
            "Train Epoch: 7 [30000/60000 (50%)]\t1.506390\n",
            "Train Epoch: 7 [32000/60000 (53%)]\t1.505775\n",
            "Train Epoch: 7 [34000/60000 (57%)]\t1.499243\n",
            "Train Epoch: 7 [36000/60000 (60%)]\t1.511821\n",
            "Train Epoch: 7 [38000/60000 (63%)]\t1.522627\n",
            "Train Epoch: 7 [40000/60000 (67%)]\t1.481478\n",
            "Train Epoch: 7 [42000/60000 (70%)]\t1.519631\n",
            "Train Epoch: 7 [44000/60000 (73%)]\t1.510403\n",
            "Train Epoch: 7 [46000/60000 (77%)]\t1.498635\n",
            "Train Epoch: 7 [48000/60000 (80%)]\t1.518006\n",
            "Train Epoch: 7 [50000/60000 (83%)]\t1.516686\n",
            "Train Epoch: 7 [52000/60000 (87%)]\t1.513946\n",
            "Train Epoch: 7 [54000/60000 (90%)]\t1.503862\n",
            "Train Epoch: 7 [56000/60000 (93%)]\t1.507951\n",
            "Train Epoch: 7 [58000/60000 (97%)]\t1.529429\n",
            "\n",
            "Test set: Average loss:  0.014815, Accuracy 9792/10000 (98%\n",
            ")\n",
            "Train Epoch: 8 [0/60000 (0%)]\t1.500242\n",
            "Train Epoch: 8 [2000/60000 (3%)]\t1.498222\n",
            "Train Epoch: 8 [4000/60000 (7%)]\t1.499230\n",
            "Train Epoch: 8 [6000/60000 (10%)]\t1.529791\n",
            "Train Epoch: 8 [8000/60000 (13%)]\t1.555025\n",
            "Train Epoch: 8 [10000/60000 (17%)]\t1.516751\n",
            "Train Epoch: 8 [12000/60000 (20%)]\t1.512750\n",
            "Train Epoch: 8 [14000/60000 (23%)]\t1.498581\n",
            "Train Epoch: 8 [16000/60000 (27%)]\t1.509079\n",
            "Train Epoch: 8 [18000/60000 (30%)]\t1.518316\n",
            "Train Epoch: 8 [20000/60000 (33%)]\t1.469478\n",
            "Train Epoch: 8 [22000/60000 (37%)]\t1.525016\n",
            "Train Epoch: 8 [24000/60000 (40%)]\t1.539575\n",
            "Train Epoch: 8 [26000/60000 (43%)]\t1.492205\n",
            "Train Epoch: 8 [28000/60000 (47%)]\t1.531555\n",
            "Train Epoch: 8 [30000/60000 (50%)]\t1.519083\n",
            "Train Epoch: 8 [32000/60000 (53%)]\t1.498213\n",
            "Train Epoch: 8 [34000/60000 (57%)]\t1.495736\n",
            "Train Epoch: 8 [36000/60000 (60%)]\t1.518073\n",
            "Train Epoch: 8 [38000/60000 (63%)]\t1.504982\n",
            "Train Epoch: 8 [40000/60000 (67%)]\t1.510710\n",
            "Train Epoch: 8 [42000/60000 (70%)]\t1.470930\n",
            "Train Epoch: 8 [44000/60000 (73%)]\t1.496283\n",
            "Train Epoch: 8 [46000/60000 (77%)]\t1.549486\n",
            "Train Epoch: 8 [48000/60000 (80%)]\t1.491082\n",
            "Train Epoch: 8 [50000/60000 (83%)]\t1.520313\n",
            "Train Epoch: 8 [52000/60000 (87%)]\t1.525135\n",
            "Train Epoch: 8 [54000/60000 (90%)]\t1.491653\n",
            "Train Epoch: 8 [56000/60000 (93%)]\t1.510321\n",
            "Train Epoch: 8 [58000/60000 (97%)]\t1.548967\n",
            "\n",
            "Test set: Average loss:  0.014807, Accuracy 9805/10000 (98%\n",
            ")\n",
            "Train Epoch: 9 [0/60000 (0%)]\t1.500696\n",
            "Train Epoch: 9 [2000/60000 (3%)]\t1.522347\n",
            "Train Epoch: 9 [4000/60000 (7%)]\t1.514206\n",
            "Train Epoch: 9 [6000/60000 (10%)]\t1.493436\n",
            "Train Epoch: 9 [8000/60000 (13%)]\t1.504219\n",
            "Train Epoch: 9 [10000/60000 (17%)]\t1.506524\n",
            "Train Epoch: 9 [12000/60000 (20%)]\t1.488358\n",
            "Train Epoch: 9 [14000/60000 (23%)]\t1.511510\n",
            "Train Epoch: 9 [16000/60000 (27%)]\t1.499518\n",
            "Train Epoch: 9 [18000/60000 (30%)]\t1.491751\n",
            "Train Epoch: 9 [20000/60000 (33%)]\t1.531298\n",
            "Train Epoch: 9 [22000/60000 (37%)]\t1.481351\n",
            "Train Epoch: 9 [24000/60000 (40%)]\t1.490947\n",
            "Train Epoch: 9 [26000/60000 (43%)]\t1.483740\n",
            "Train Epoch: 9 [28000/60000 (47%)]\t1.502289\n",
            "Train Epoch: 9 [30000/60000 (50%)]\t1.472036\n",
            "Train Epoch: 9 [32000/60000 (53%)]\t1.482171\n",
            "Train Epoch: 9 [34000/60000 (57%)]\t1.508407\n",
            "Train Epoch: 9 [36000/60000 (60%)]\t1.537837\n",
            "Train Epoch: 9 [38000/60000 (63%)]\t1.502662\n",
            "Train Epoch: 9 [40000/60000 (67%)]\t1.500153\n",
            "Train Epoch: 9 [42000/60000 (70%)]\t1.551476\n",
            "Train Epoch: 9 [44000/60000 (73%)]\t1.503193\n",
            "Train Epoch: 9 [46000/60000 (77%)]\t1.513358\n",
            "Train Epoch: 9 [48000/60000 (80%)]\t1.548746\n",
            "Train Epoch: 9 [50000/60000 (83%)]\t1.511103\n",
            "Train Epoch: 9 [52000/60000 (87%)]\t1.503446\n",
            "Train Epoch: 9 [54000/60000 (90%)]\t1.522581\n",
            "Train Epoch: 9 [56000/60000 (93%)]\t1.502106\n",
            "Train Epoch: 9 [58000/60000 (97%)]\t1.526055\n",
            "\n",
            "Test set: Average loss:  0.014797, Accuracy 9814/10000 (98%\n",
            ")\n",
            "Train Epoch: 10 [0/60000 (0%)]\t1.522894\n",
            "Train Epoch: 10 [2000/60000 (3%)]\t1.493200\n",
            "Train Epoch: 10 [4000/60000 (7%)]\t1.537791\n",
            "Train Epoch: 10 [6000/60000 (10%)]\t1.488845\n",
            "Train Epoch: 10 [8000/60000 (13%)]\t1.500821\n",
            "Train Epoch: 10 [10000/60000 (17%)]\t1.506822\n",
            "Train Epoch: 10 [12000/60000 (20%)]\t1.495373\n",
            "Train Epoch: 10 [14000/60000 (23%)]\t1.531420\n",
            "Train Epoch: 10 [16000/60000 (27%)]\t1.484149\n",
            "Train Epoch: 10 [18000/60000 (30%)]\t1.528352\n",
            "Train Epoch: 10 [20000/60000 (33%)]\t1.550612\n",
            "Train Epoch: 10 [22000/60000 (37%)]\t1.487734\n",
            "Train Epoch: 10 [24000/60000 (40%)]\t1.508625\n",
            "Train Epoch: 10 [26000/60000 (43%)]\t1.495549\n",
            "Train Epoch: 10 [28000/60000 (47%)]\t1.512952\n",
            "Train Epoch: 10 [30000/60000 (50%)]\t1.479885\n",
            "Train Epoch: 10 [32000/60000 (53%)]\t1.511296\n",
            "Train Epoch: 10 [34000/60000 (57%)]\t1.492162\n",
            "Train Epoch: 10 [36000/60000 (60%)]\t1.495818\n",
            "Train Epoch: 10 [38000/60000 (63%)]\t1.503350\n",
            "Train Epoch: 10 [40000/60000 (67%)]\t1.493791\n",
            "Train Epoch: 10 [42000/60000 (70%)]\t1.500659\n",
            "Train Epoch: 10 [44000/60000 (73%)]\t1.472932\n",
            "Train Epoch: 10 [46000/60000 (77%)]\t1.510028\n",
            "Train Epoch: 10 [48000/60000 (80%)]\t1.504365\n",
            "Train Epoch: 10 [50000/60000 (83%)]\t1.523691\n",
            "Train Epoch: 10 [52000/60000 (87%)]\t1.492273\n",
            "Train Epoch: 10 [54000/60000 (90%)]\t1.508170\n",
            "Train Epoch: 10 [56000/60000 (93%)]\t1.527535\n",
            "Train Epoch: 10 [58000/60000 (97%)]\t1.543445\n",
            "\n",
            "Test set: Average loss:  0.014797, Accuracy 9813/10000 (98%\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "data, target = test_data[5]\n",
        "data = data.unsqueeze(0).to(device)\n",
        "output = model(data)\n",
        "prediction = output.argmax(dim=1, keepdim=True).item()\n",
        "print(f\"Prediction: {prediction}\")\n",
        "\n",
        "image = data.squeeze(0).squeeze(0).cpu().numpy()\n",
        "\n",
        "plt.imshow(image, cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "# There we go! We predicted that it will be number 1 and we were correct!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "zGxZTWLpQk7J",
        "outputId": "3bb20d50-7fc5-45c5-f51f-2efcb06ab244"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-0a9cb36f43b8>:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.softmax(x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: 1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mRFFbuCGTAbv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}